{"metadata":{"kernelspec":{"display_name":"deepL","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.11"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/mateorbt/notebookcece29c675?scriptVersionId=245116532\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# Import necessary libraries\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\n# Download necessary NLTK data\nimport nltk\nfrom jupyter_core.version import pattern\n\nnltk.download('punkt')\nnltk.download('stopwords')\n","metadata":{"ExecuteTime":{"end_time":"2025-01-08T17:48:21.816302Z","start_time":"2025-01-08T17:48:21.331275Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Load and display the data\n","metadata":{}},{"cell_type":"code","source":"# Define the path to the manually downloaded dataset\ndata_path = \"data/data.csv\"  # Update the file name if it's different\n\n# Check if the file exists before attempting to load\nif not os.path.exists(data_path):\n    raise FileNotFoundError(f\"Dataset file not found at {data_path}. Ensure the file is in the correct location.\")\n\n# Load the dataset\ndf= pd.read_csv(data_path)\nprint(\"Dataset loaded successfully!\")\n\n# Display the first few rows of the DataFrame\ndf.head()\n","metadata":{"ExecuteTime":{"end_time":"2025-01-08T17:48:21.848062Z","start_time":"2025-01-08T17:48:21.823403Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Perform EDA ","metadata":{}},{"cell_type":"markdown","source":"# Display class disctribution","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n# Perform Exploratory Data Analysis (EDA)\n# drop rows with missing values\ndf.dropna(inplace=True)\n# Check for duplicates and remove them\ndf.drop_duplicates(inplace=True)\ndef perform_eda(data):\n    # Check class distribution\n    print(\"Class distribution:\")\n    print(df['Sentiment'].value_counts())\n\n    # Text length analysis\n    df['text_length'] = df['Sentence'].apply(len)\n    print(\"\\nText length stats:\")\n    print(df['text_length'].describe())\n\n    # Visualize class distribution\n    df['Sentiment'].value_counts().plot(kind='bar', title=\"Class Distribution\")\n    plt.show()\nperform_eda(df)\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Preprocess the text data\n","metadata":{}},{"cell_type":"code","source":"import nltk\nimport re\nimport html\n\n\n# Download necessary NLTK resources if not already done\nnltk.download('punkt')\nnltk.download('stopwords')\nnltk.download('wordnet')\n\ndef clean_df(text):\n    # Remove extra whitespaces\n    text = re.sub(r'\\s+', ' ', text)\n\n    # Remove HTML tags\n    text = re.sub(r'<.*?>', '', text)\n\n    # Decode HTML entities\n    text = html.unescape(text)\n\n    # Replace URLs with a placeholder\n    text = re.sub(r'http\\S+|www\\S+|https\\S+', 'url', text)\n\n    # Strip leading/trailing whitespace\n    return text.strip()\n    \n\n# Apply the cleaning function to the 'Sentence' column and create a new column 'cleaned_text'\ndf['cleaned_text'] = df['Sentence'].apply(clean_df)\ndf.head(100)\n","metadata":{"ExecuteTime":{"end_time":"2025-01-08T17:48:22.699228Z","start_time":"2025-01-08T17:48:22.075968Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Handle imbalance","metadata":{}},{"cell_type":"code","source":"from sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.model_selection import train_test_split\nimport torch\nimport numpy as np\n\n# Χαρτογράφηση των labels σε ακέραιους\nlabel_mapping = {'positive': 0, 'negative': 1, 'neutral': 2}\ndf['label'] = df['Sentiment'].map(label_mapping)\n\n# Προετοιμασία δεδομένων\ntexts = df['cleaned_text'].tolist()\nlabels = df['label'].tolist()\n\n# Train/Validation split\ntrain_texts, val_texts, train_labels, val_labels = train_test_split(\n    texts, labels, test_size=0.2, stratify=labels, random_state=42\n)\n\n# Υπολογισμός class weights βάσει του training set\ntrain_labels_np = np.array(train_labels)\nclass_weights = compute_class_weight(\n    class_weight='balanced',\n    classes=np.unique(train_labels_np),\n    y=train_labels_np\n)\n\n\nclass_weights_tensor = torch.tensor(class_weights, dtype=torch.float32)\n\n# Εκτύπωση για έλεγχο\nprint(\"Class weights:\", class_weights_tensor)\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# focal loss function from \ncode was found on github page https://github.com/itakurah/Focal-loss-PyTorch","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass FocalLoss(nn.Module):\n    def __init__(self, gamma=2, alpha=None, reduction='mean', task_type='binary', num_classes=None):\n        \"\"\"\n        Unified Focal Loss class for binary, multi-class, and multi-label classification tasks.\n        :param gamma: Focusing parameter, controls the strength of the modulating factor (1 - p_t)^gamma\n        :param alpha: Balancing factor, can be a scalar or a tensor for class-wise weights. If None, no class balancing is used.\n        :param reduction: Specifies the reduction method: 'none' | 'mean' | 'sum'\n        :param task_type: Specifies the type of task: 'binary', 'multi-class', or 'multi-label'\n        :param num_classes: Number of classes (only required for multi-class classification)\n        \"\"\"\n        super(FocalLoss, self).__init__()\n        self.gamma = gamma\n        self.alpha = alpha\n        self.reduction = reduction\n        self.task_type = task_type\n        self.num_classes = num_classes\n\n        # Handle alpha for class balancing in multi-class tasks\n        if task_type == 'multi-class' and alpha is not None and isinstance(alpha, (list, torch.Tensor)):\n            assert num_classes is not None, \"num_classes must be specified for multi-class classification\"\n            if isinstance(alpha, list):\n                self.alpha = torch.Tensor(alpha)\n            else:\n                self.alpha = alpha\n\n    def forward(self, inputs, targets):\n        \"\"\"\n        Forward pass to compute the Focal Loss based on the specified task type.\n        :param inputs: Predictions (logits) from the model.\n                       Shape:\n                         - binary/multi-label: (batch_size, num_classes)\n                         - multi-class: (batch_size, num_classes)\n        :param targets: Ground truth labels.\n                        Shape:\n                         - binary: (batch_size,)\n                         - multi-label: (batch_size, num_classes)\n                         - multi-class: (batch_size,)\n        \"\"\"\n        if self.task_type == 'binary':\n            return self.binary_focal_loss(inputs, targets)\n        elif self.task_type == 'multi-class':\n            return self.multi_class_focal_loss(inputs, targets)\n        elif self.task_type == 'multi-label':\n            return self.multi_label_focal_loss(inputs, targets)\n        else:\n            raise ValueError(\n                f\"Unsupported task_type '{self.task_type}'. Use 'binary', 'multi-class', or 'multi-label'.\")\n\n    def binary_focal_loss(self, inputs, targets):\n        \"\"\" Focal loss for binary classification. \"\"\"\n        probs = torch.sigmoid(inputs)\n        targets = targets.float()\n\n        # Compute binary cross entropy\n        bce_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n\n        # Compute focal weight\n        p_t = probs * targets + (1 - probs) * (1 - targets)\n        focal_weight = (1 - p_t) ** self.gamma\n\n        # Apply alpha if provided\n        if self.alpha is not None:\n            alpha_t = self.alpha * targets + (1 - self.alpha) * (1 - targets)\n            bce_loss = alpha_t * bce_loss\n\n        # Apply focal loss weighting\n        loss = focal_weight * bce_loss\n\n        if self.reduction == 'mean':\n            return loss.mean()\n        elif self.reduction == 'sum':\n            return loss.sum()\n        return loss\n\n    def multi_class_focal_loss(self, inputs, targets):\n        \"\"\" Focal loss for multi-class classification. \"\"\"\n        if self.alpha is not None:\n            alpha = self.alpha.to(inputs.device)\n\n        # Convert logits to probabilities with softmax\n        probs = F.softmax(inputs, dim=1)\n\n        # One-hot encode the targets\n        targets_one_hot = F.one_hot(targets, num_classes=self.num_classes).float()\n\n        # Compute cross-entropy for each class\n        ce_loss = -targets_one_hot * torch.log(probs)\n\n        # Compute focal weight\n        p_t = torch.sum(probs * targets_one_hot, dim=1)  # p_t for each sample\n        focal_weight = (1 - p_t) ** self.gamma\n\n        # Apply alpha if provided (per-class weighting)\n        if self.alpha is not None:\n            alpha_t = alpha.gather(0, targets)\n            ce_loss = alpha_t.unsqueeze(1) * ce_loss\n\n        # Apply focal loss weight\n        loss = focal_weight.unsqueeze(1) * ce_loss\n\n        if self.reduction == 'mean':\n            return loss.mean()\n        elif self.reduction == 'sum':\n            return loss.sum()\n        return loss\n\n    def multi_label_focal_loss(self, inputs, targets):\n        \"\"\" Focal loss for multi-label classification. \"\"\"\n        probs = torch.sigmoid(inputs)\n\n        # Compute binary cross entropy\n        bce_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n\n        # Compute focal weight\n        p_t = probs * targets + (1 - probs) * (1 - targets)\n        focal_weight = (1 - p_t) ** self.gamma\n\n        # Apply alpha if provided\n        if self.alpha is not None:\n            alpha_t = self.alpha * targets + (1 - self.alpha) * (1 - targets)\n            bce_loss = alpha_t * bce_loss\n\n        # Apply focal loss weight\n        loss = focal_weight * bce_loss\n\n        if self.reduction == 'mean':\n            return loss.mean()\n        elif self.reduction == 'sum':\n            return loss.sum()\n        return loss\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Create model \nthe model we will use is finbert ","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\nfrom transformers import AutoConfig\nfrom transformers import TrainerCallback, EarlyStoppingCallback\nimport torch\nimport numpy as np\nfrom sklearn.metrics import accuracy_score\n\n# Tokenizer και model\ntokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n\nconfig = AutoConfig.from_pretrained(\n    \"ProsusAI/finbert\",\n    num_labels=3,\n    hidden_dropout_prob=0.3,               \n    attention_probs_dropout_prob=0.3       \n)\n\nmodel = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\",config=config)\n\n# Dataset class\nclass FinDataset(torch.utils.data.Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        item['labels'] = torch.tensor(self.labels[idx])\n        return item\n\n    def __len__(self):\n        return len(self.labels)\n\n\n\n\n\n\n# Tokenization\ntrain_enc = tokenizer(train_texts, truncation=True, padding='max_length', max_length=160)\nval_enc = tokenizer(val_texts, truncation=True, padding='max_length', max_length=160)\n\n# Datasets\ntrain_dataset = FinDataset(train_enc, train_labels)\nval_dataset = FinDataset(val_enc, val_labels)\n\n# Metrics function για accuracy\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    preds = np.argmax(logits, axis=1)\n    acc = accuracy_score(labels, preds)\n    return {'accuracy': acc}\n\n# Custom Trainer class for Focal Loss\nclass MyTrainer(Trainer):\n    def __init__(self, *args, class_weights=None, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.class_weights = class_weights.to(self.model.device) if class_weights is not None else None\n\n    def compute_loss(self, model, inputs, return_outputs=False):\n        labels = inputs.get(\"labels\")\n        outputs = model(**inputs)\n        logits = outputs.get(\"logits\")\n        if self.class_weights is not None:\n            loss_fct = FocalLoss(\n                gamma=2,\n                alpha=self.class_weights * 3,\n                reduction='mean',\n                task_type='multi-class',\n                num_classes=3\n            )\n            loss = loss_fct(logits, labels)\n        else:\n            loss = outputs.loss\n        return (loss, outputs) if return_outputs else loss\n    \nclass SaveMetricsCallback(TrainerCallback):\n    def __init__(self):\n        self.train_loss = []\n        self.val_loss = []\n        self.train_acc = []\n        self.val_acc = []\n\n    def on_evaluate(self, args, state, control, metrics, **kwargs):\n        # Called at the end of evaluation\n        if 'eval_loss' in metrics:\n            self.val_loss.append(metrics['eval_loss'])\n        if 'eval_accuracy' in metrics:\n            self.val_acc.append(metrics['eval_accuracy'])\n\n    def on_log(self, args, state, control, logs=None, **kwargs):\n        # Called during training logging\n        if logs is not None:\n            if 'loss' in logs:\n                self.train_loss.append(logs['loss'])\n            if 'accuracy' in logs:\n                self.train_acc.append(logs['accuracy'])\n\n    \nsave_metrics_callback = SaveMetricsCallback()   \n# Training arguments\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",\n    per_device_train_batch_size=64,\n    per_device_eval_batch_size=64,\n    num_train_epochs=10,\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    logging_strategy=\"epoch\",\n    load_best_model_at_end=True,\n    metric_for_best_model=\"accuracy\",\n    greater_is_better=True,\n    report_to=\"none\",\n    learning_rate=1e-5,\n    weight_decay=0.02,\n    lr_scheduler_type=\"reduce_lr_on_plateau\",      \n    warmup_ratio=0.1,                   \n)\n\n# Trainer\ntrainer = MyTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    compute_metrics=compute_metrics,\n    class_weights=class_weights_tensor,\n    callbacks=[\n        save_metrics_callback,\n        EarlyStoppingCallback(early_stopping_patience=3)\n    ]\n)\n\n# Train the model\ntrainer.train()\n\n# measure train and validation metrics\ntrain_metrics = trainer.evaluate(train_dataset)\nval_metrics = trainer.evaluate(val_dataset)\n\nprint(f\"Train Loss: {train_metrics['eval_loss']:.4f}, Train Accuracy: {train_metrics['eval_accuracy']:.4f}\")\nprint(f\"Val Loss: {val_metrics['eval_loss']:.4f}, Val Accuracy: {val_metrics['eval_accuracy']:.4f}\")\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# print classification report\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\n\nval_preds = trainer.predict(val_dataset)\nval_preds = np.argmax(val_preds.predictions, axis=1)\nprint(\"Validation Classification Report:\")\nprint(classification_report(val_labels, val_preds, target_names=['positive', 'negative', 'neutral']))\n\n# confusion matrix\nconf_matrix = confusion_matrix(val_labels, val_preds)\nplt.figure(figsize=(8, 6))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['positive', 'negative', 'neutral'], yticklabels=['positive', 'negative', 'neutral'])\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted')\nplt.ylabel('True Label')\nplt.tight_layout()\nplt.show()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# macro avg\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import precision_score, recall_score ,accuracy_score\nmacro_f1 = f1_score(val_labels, val_preds, average='weighted')\nmacro_precision = precision_score(val_labels, val_preds, average='weighted')\nmacro_recall = recall_score(val_labels, val_preds, average='weighted')\nmacro_accuracy = accuracy_score(val_labels, val_preds)\nprint(f\"Weighted Accuracy: {macro_accuracy:.4f}\")\nprint(f\"Weighted F1 Score: {macro_f1:.4f}\")\nprint(f\"Weighted Precision: {macro_precision:.4f}\")\nprint(f\"Weighted Recall: {macro_recall:.4f}\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# plot training loss\nimport matplotlib.pyplot as plt\ndef plot_training_loss(callback):\n    plt.figure(figsize=(10, 5))\n    plt.plot(callback.train_loss, label='Train Loss', color='blue')\n    plt.plot(callback.val_loss, label='Validation Loss', color='orange')\n    plt.title('Training Loss')\n    plt.title('Training and Validation Loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.grid()\n    plt.show()\n    \nplot_training_loss(save_metrics_callback)\n\n\n\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# print model architecture\nprint(model)\n","metadata":{},"outputs":[],"execution_count":null}]}